<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Training a language model from scratch | About me</title>
<meta name="keywords" content="nlp, transformer, machine learning">
<meta name="description" content="Hi,
This post is a short overview over a work project, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I&rsquo;m not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.
A language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.">
<meta name="author" content="">
<link rel="canonical" href="https://steffenhaeussler.github.io/posts/2023-04-21-training/llm/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.c32c3fa257f14f25741bf9b4bf26c500e50fe88bb7915cdb5f59134fcd019ee5.css" integrity="sha256-wyw/olfxTyV0G/m0vybFAOUP6Iu3kVzbX1kTT80BnuU=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://steffenhaeussler.github.io/assets/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://steffenhaeussler.github.io/assets/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://steffenhaeussler.github.io/assets/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://steffenhaeussler.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://steffenhaeussler.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://steffenhaeussler.github.io/posts/2023-04-21-training/llm/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>


<meta property="og:url" content="https://steffenhaeussler.github.io/posts/2023-04-21-training/llm/">
  <meta property="og:site_name" content="About me">
  <meta property="og:title" content="Training a language model from scratch">
  <meta property="og:description" content="Hi,
This post is a short overview over a work project, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I‚Äôm not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.
A language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-04-15T10:30:58+01:00">
    <meta property="article:modified_time" content="2023-04-15T10:30:58+01:00">
    <meta property="article:tag" content="Nlp">
    <meta property="article:tag" content="Transformer">
    <meta property="article:tag" content="Machine Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Training a language model from scratch">
<meta name="twitter:description" content="Hi,
This post is a short overview over a work project, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I&rsquo;m not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.
A language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://steffenhaeussler.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Training a language model from scratch",
      "item": "https://steffenhaeussler.github.io/posts/2023-04-21-training/llm/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Training a language model from scratch",
  "name": "Training a language model from scratch",
  "description": "Hi,\nThis post is a short overview over a work project, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I\u0026rsquo;m not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.\nA language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.\n",
  "keywords": [
    "nlp", "transformer", "machine learning"
  ],
  "articleBody": "Hi,\nThis post is a short overview over a work project, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I‚Äôm not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.\nA language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.\nLanguage models can be used for a variety of natural language processing (NLP) tasks, such as text classification, machine translation, text summarization, speech recognition, and sentiment analysis. There are many types of language models, ranging from simple n-gram models to more complex neural network-based models such as recurrent neural networks (RNNs) and transformers.\nThe transformer architecture is currently mostly used for language models and can be divided into an encoder and/or decoder architecture depending on the specific task. In general, transformers are trained on a large quantity of unlabeled text using self-supervised learning. The training of a transformer model on a lot of data takes a lot of computational effort and the training of language models can get expensive very quickly. So, often the best way to have a task-specific transformer model is to use a pre-trained model from Hugging Face and fine-tune the model based on your data.\nBased on my work experience with invoices, fine-tuning a pre-existing model didn‚Äôt work well. I received the best results for text classification after fine-tuning a french base-model on german invoices. Nevertheless the overall F1-score wasn‚Äôt worth the effort. I assume that the content and structure of an invoice differs too much from the training data (e.g. no continuous text and many numbers). Additional, the tokenizers of the pre-trained models are not optimied for invoices, so the context window of a transformer will contain less text, which makes the training less effective.\nI worked on text classification of invoices for multiple clients. I trained a base-model on a few million invoices (mostly german and english) and fine-tuned the base model for each client with around 2000 - 50000 invoices and 70 - 2000 labels. Initially I used the Longformer architecture (Beltagy et al. 2020), but a bug prevented the model deployment. Besides its limitations, I used the BERT architecture Devlin et al. 2019. Hugging Face also provides a tutorial for training language models. .\nTokenizer A tokenizer converts raw text into smaller units, such as words or subwords, that can be used for training machine learning models. The tokenizer takes as input a string of text and outputs a sequence of tokens, each of which represents a distinct unit of meaning. The subword tokenizer breaks down words into smaller subword units. This is useful for handling out-of-vocabulary (OOV) words, which are words that are not in the training data.\nThe Byte-Pair Encoding tokenizer replaces the most common pair of consecutive bytes with bytes that does not occur in that data (Gage 1994, Sennrich et al. 2016).\nFirst, we define our BPE tokenizer with the preprocessing steps for the incoming text data. As normalization we use unicode-normalization and set the text to lower case. Further preprocessing steps are a ByteLevel representation of the text followed by splitting the text by whitespaces. As a last step, we decode a tokenized input to the original one.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from tokenizers import normalizers from tokenizers.decoders import ByteLevel as ByteLevelDecoder from tokenizers.normalizers import NFD, Lowercase, NFKC from tokenizers import pre_tokenizers from tokenizers.pre_tokenizers import Whitespace, ByteLevel from tokenizers import Tokenizer, models, trainers tokenizer = Tokenizer(models.BPE()) tokenizer.normalizer = normalizers.Sequence([ NFD(), Lowercase() ]) # Our tokenizer also needs a pre-tokenizer responsible for converting the input to a ByteLevel representation. tokenizer.pre_tokenizer = pre_tokenizers.Sequence([ ByteLevel(add_prefix_space=False), Whitespace() ]) tokenizer.decoder = ByteLevelDecoder() We define the vocabulary size of the tokenizer, add the special tokens and define the initial alphabet. The provided batch iterator trains the tokenizer from our streaming data.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 from transformers.models.gpt2.tokenization_gpt2 import bytes_to_unicode def batch_iterator(batch_size=10): for _ in tqdm(range(0, round(train_length,-1), batch_size)): yield [next(iter_dataset)['text'] for _ in range(batch_size)] vocab_size=32768 byte_to_unicode_map = bytes_to_unicode() unicode_to_byte_map = dict((v, k) for k, v in byte_to_unicode_map.items()) base_vocab = list(unicode_to_byte_map.keys()) trainer = trainers.BpeTrainer(vocab_size=vocab_size, show_progress=True, initial_alphabet=base_vocab, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]) iter_dataset = iter(train_dataset) tokenizer.train_from_iterator(batch_iterator(), trainer=trainer) Here is an example of the tokenizer output\n1 2 3 4 5 6 7 8 9 10 output = tokenizer.encode(\"Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.\") print(output.tokens) \u003e\u003e ['die', 'ƒ†authent', 'if', 'ikation', 'ƒ†wird', 'ƒ†mit', 'ƒ†open', 'l', 'da', 'p', 'ƒ†erledigt', ',', 'ƒ†die', 'ƒ†einrichtung', 'ƒ†oder', 'ƒ†aktualisierung', 'ƒ†von', 'ƒ†systemen', 'ƒ†mit', 'ƒ†y', 'um', 'ƒ†und', 'ƒ†servern', 'ƒ†f√É', '¬º', 'r', 'ƒ†dns', ',', 'ƒ†d', 'hc', 'p', 'ƒ†und', 'ƒ†t', 'ft', 'p', '.'] print(output.ids) \u003e\u003e [373, 12466, 997, 2887, 468, 341, 4256, 80, 609, 84, 11738, 16, 282, 9128, 550, 19260, 355, 18058, 341, 1312, 349, 309, 20238, 348, 125, 86, 31306, 16, 264, 25171, 84, 309, 328, 367, 84, 18] Data pipeline The training data is stored in multiple parquet files and split into a training and evaluation dataset in a preprocessing step. I used a train-test split of 0.01. Since the data doesn‚Äôt fit into memory, the data is streaming from disk. The text will be padded or truncated to the defined context length. The data collator for masked language modeling masks the incoming text data to allow the model training.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 from datasets import load_dataset from transformers import DataCollatorForLanguageModeling train_dataset = load_dataset( 'parquet', data_dir=\"train_data/\", streaming=True, split=\"train\" ) eval_dataset = load_dataset( 'parquet', data_dir=\"eval_data/\", streaming=True, split=\"train\" ) train_dataset = train_dataset.map( lambda x: tokenizer.batch_encode_plus( x['text'], padding=True, truncation=True, max_length=max_length), batched=True) eval_dataset = eval_dataset.map( lambda x: tokenizer.batch_encode_plus( x['text'], padding=True, truncation=True, max_length=max_length), batched=True) train_dataset = train_dataset.with_format(\"torch\") eval_dataset = eval_dataset.with_format(\"torch\") data_collator = DataCollatorForLanguageModeling( tokenizer=tokenizer, mlm=use_mlm, mlm_probability=mlm_probability ) Model Training So far, the data is processed, the data streaming is set up and a tokenizer is trained. Finally the model training can start. I follow the BERT architecture Devlin et al. 2019 and use their initial setup and hyperparameters. The model is trained via masked language modelling, where 20 % of the tokens will be randomly masked. From those 20% of masked tokens, 80 % will be untouched, 10 % will be replaced with random tokens and 10 % will be replaced with the original tokens. Hugging Face provides an implementation for it. Wettig et al. 2023 scrutinized the impact of the mlm parameters towards the model result.\nHere is an example, which shows some randomly mask tokens from an incoming text. The model is trained on predicting the masked tokens based on the context of the whole sentence.\n1 2 3 4 5 6 7 8 9 10 11 print(f\"Mask Token id: {tokenizer.mask_token_id}\") \u003e\u003e Mask Token id: 4 output = tokenizer.encode(\"Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.\") masked = random.sample(range(0, 36), 7) for mask in masked: output[mask] = tokenizer.mask_token_id print(f\"Masked encoding: {tokenizer.decode(output)}\") \u003e\u003e Masked encoding: [MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] f[MASK]r dns, dhcp und tftp. I‚Äôm not a big fan of using too many libraries, but I didn‚Äôt have enough time to set up the BERT model with Pytorch. I go the happy dependancy path and use the transformer library. Probably, I will create another post, where I describe the transition from the transformer library to plain pytorch.\nI use the standard BERT configuration with eight attention layers with eight attention heads for each layer. A context size of 512 will truncate multiple invoices, but some experiments indicate that the overall effect can be neglected on the model performance . To understand the attention mechanism better, please follow my short blog post.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 from transformers import BertConfig, BertForMaskedLM use_mlm = True mlm_probability = 0.2 # still keeping the 80 - 10 - 10 rule max_length=512 block_size = 512 max_position_embeddings = 512 hidden_size = 768 num_hidden_layers = 8 num_attention_heads = 8 intermediate_size = 3072 drop_out = 0.1 config = BertConfig( # attention_window = [block_size]*num_attention_heads, # mask_token_id = 4, bos_token_id = 1, sep_token_id = 2, # pad_token_id = 3, eos_token_id = 2, max_position_embeddings = max_position_embeddings, hidden_size = hidden_size, num_hidden_layers = num_hidden_layers, num_attention_heads = num_attention_heads, intermediate_size = intermediate_size, hidden_act = 'gelu', hidden_dropout_prob = drop_out, attention_probs_dropout_prob = drop_out, type_vocab_size = 2, initializer_range = 0.02, layer_norm_eps = 1e-12, vocab_size = vocab_size, use_cache = True, classifier_dropout = None, onnx_export = False) model = BertForMaskedLM(config=config) print(f\"n of parameters: {model.num_parameters():_}\") \u003e\u003e n of parameters: 82_820_774 The model will use 82 million parameters. Depending on the data size and GPUs, it will train less than 1,5 weeks on 4x T4 GPUs. The model train for five epochs with the AdamW optimizer Loshchilov \u0026 Hutter 2019 and used the learning rate published in the BERT paper with the same weight decay parameters. The batch size is optimized for maximum utilization of the GPU memory. The gradient accumulation step updates the model weights with a batch size of 64. To speed up training, we use fp16.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 from transformers import Trainer, TrainingArguments, EarlyStoppingCallback learning_rate = 1e-4 # bert weight_decay = 1e-2 # bert lr_scheduler_type = \"linear\" num_train_epochs = 5 train_batch_size = 32 eval_batch_size = 32 gradient_accumulation_steps=2 eval_accumulation_steps=2 warmup_steps = 1_000 adam_beta1 = 0.9 # bert adam_beta2 = 0.999 # bert adam_epsilon = 1e-8 # bert max_grad_norm = 1.0 # bert max_steps=num_train_epochs*train_length//train_batch_size training_args = TrainingArguments( output_dir=model_path, overwrite_output_dir=True, learning_rate=learning_rate, weight_decay=weight_decay, lr_scheduler_type=lr_scheduler_type, num_train_epochs=num_train_epochs, adam_beta1=adam_beta1, adam_beta2=adam_beta2, adam_epsilon=adam_epsilon, max_grad_norm=max_grad_norm, evaluation_strategy=\"steps\", eval_steps=5_000, max_steps=max_steps, per_device_train_batch_size=train_batch_size, # depends on memory per_device_eval_batch_size=eval_batch_size, gradient_accumulation_steps=gradient_accumulation_steps, save_strategy=\"steps\", save_steps=5_000, save_total_limit=3, prediction_loss_only=False, report_to=\"tensorboard\", log_level=\"warning\", logging_strategy=\"steps\", fp16 = True, fp16_full_eval=True, load_best_model_at_end=True, metric_for_best_model=\"loss\", greater_is_better=False, push_to_hub=False, dataloader_pin_memory=True, ) early_stopping = EarlyStoppingCallback(early_stopping_patience = 3, early_stopping_threshold = 0.02) callbacks = [early_stopping] trainer = Trainer( model=model, args=training_args, data_collator=data_collator, train_dataset=train_dataset, # compute_metrics=compute_metrics, eval_dataset=eval_dataset, tokenizer=tokenizer, callbacks=callbacks ) Finally, everything is set up, and we can train our model. Depending on the data, model, and budget size, you can enjoy your holidays, and hopefully, the model training is finished, when you come back.\n1 2 3 trainer.train() trainer.save_model(f\"{model_path}/main/\") As a final step, we can evaluate the model output. Since I can‚Äôt share any data, I use the output from my Kaggle notebook. For\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 from transformers import pipeline original_text = \"Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.\") masked_text = \"[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] f[MASK]r dns, dhcp und tftp.\" mask_filler = pipeline(\"fill-mask\",f\"{model_path}/main/\") mask_filler(tokenizer.decode(output), top_k=3) \u003e\u003e [[{'score': 0.8014500737190247, \u003e\u003e 'token': 373, \u003e\u003e 'token_str': 'die', \u003e\u003e 'sequence': 'die[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.08444128930568695, \u003e\u003e 'token': 517, \u003e\u003e 'token_str': 'eine', \u003e\u003e 'sequence': 'eine[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.028047803789377213, \u003e\u003e 'token': 1384, \u003e\u003e 'token_str': 'diese', \u003e\u003e 'sequence': 'diese[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.03110463358461857, \u003e\u003e 'token': 4354, \u003e\u003e 'token_str': 'zert', \u003e\u003e 'sequence': '[MASK]zertifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.030949348583817482, \u003e\u003e 'token': 1160, \u003e\u003e 'token_str': ' ant', \u003e\u003e 'sequence': '[MASK] antifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.02660573646426201, \u003e\u003e 'token': 12466, \u003e\u003e 'token_str': ' authent', \u003e\u003e 'sequence': '[MASK] authentifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.021829063072800636, \u003e\u003e 'token': 1202, \u003e\u003e 'token_str': ' per', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit perldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.018226258456707, \u003e\u003e 'token': 307, \u003e\u003e 'token_str': ' p', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit pldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.013632726855576038, \u003e\u003e 'token': 276, \u003e\u003e 'token_str': ' m', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit mldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.46616730093955994, \u003e\u003e 'token': 489, \u003e\u003e 'token_str': ' einer', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung einer aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.26918938755989075, \u003e\u003e 'token': 288, \u003e\u003e 'token_str': ' der', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung der aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.05999871343374252, \u003e\u003e 'token': 533, \u003e\u003e 'token_str': ' zur', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung zur aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.19769684970378876, \u003e\u003e 'token': 2150, \u003e\u003e 'token_str': ' nov', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit novum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.03822920098900795, \u003e\u003e 'token': 1504, \u003e\u003e 'token_str': ' vol', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit volum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.030768193304538727, \u003e\u003e 'token': 17401, \u003e\u003e 'token_str': ' quant', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit quantum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.0999603122472763, \u003e\u003e 'token': 386, \u003e\u003e 'token_str': ' dem', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und dem fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.07762913405895233, \u003e\u003e 'token': 288, \u003e\u003e 'token_str': ' der', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und der fÔøΩ[MASK]r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.055170487612485886, \u003e\u003e 'token': 332, \u003e\u003e 'token_str': ' den', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und den fÔøΩ[MASK]r dns, dhcp und tftp.'}], \u003e\u003e [{'score': 0.690095841884613, \u003e\u003e 'token': 125, \u003e\u003e 'token_str': 'ÔøΩ', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩÔøΩr dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.029322009533643723, \u003e\u003e 'token': 12, \u003e\u003e 'token_str': '(', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ(r dns, dhcp und tftp.'}, \u003e\u003e {'score': 0.01887478120625019, \u003e\u003e 'token': 4585, \u003e\u003e 'token_str': ' pet', \u003e\u003e 'sequence': '[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ petr dns, dhcp und tftp.'}]] Fine-tuning For fine-tuning the language model, you can use the script above. The pre-trained model weights can be loaded into a classification model. The BertForSequenceClassification changes only the head from a MaskedLMHead to a ClassifierHead. All the other model weights will stay the same. Also, the data collator has to be adapted, and we output some metrics for the evaluation. That‚Äôs all.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score from transformers import BertForSequenceClassification, DataCollatorWithPadding def compute_metrics(eval_pred): logits, labels = eval_pred predictions = np.argmax(logits, axis=-1) accuracy = accuracy_score(y_true=labels, y_pred=predictions) recall = recall_score(y_true=labels, y_pred=predictions, average='weighted') precision = precision_score(y_true=labels, y_pred=predictions, average='weighted') f1 = f1_score(y_true=labels, y_pred=predictions, average='weighted') return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1} data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=block_size) model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_label) Thank you for your attention.\n",
  "wordCount" : "2782",
  "inLanguage": "en",
  "datePublished": "2023-04-15T10:30:58+01:00",
  "dateModified": "2023-04-15T10:30:58+01:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://steffenhaeussler.github.io/posts/2023-04-21-training/llm/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "About me",
    "logo": {
      "@type": "ImageObject",
      "url": "https://steffenhaeussler.github.io/assets/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://steffenhaeussler.github.io/" accesskey="h" title="About me (Alt + H)">About me</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
                <ul class="lang-switch"><li>|</li>
                </ul>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://steffenhaeussler.github.io/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://steffenhaeussler.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://steffenhaeussler.github.io/archives/" title="Archives">
                    <span>Archives</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://steffenhaeussler.github.io/">Home</a>&nbsp;¬ª&nbsp;<a href="https://steffenhaeussler.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Training a language model from scratch
    </h1>
    <div class="post-meta"><span title='2023-04-15 10:30:58 +0100 +0100'>April 15, 2023</span>&nbsp;¬∑&nbsp;14 min

</div>
  </header> 
  <div class="post-content"><p>Hi,</p>
<p>This post is a short overview over a <a href="https://www.kaggle.com/code/steffenhaeussler/train-a-language-model-from-scratch/notebook">work project</a>, where I trained a language model for invoices. This so-called base model is then fine-tuned for text classification on customer data. Due to data privacy, a non-disclosure agreement, ISO 27001 and SOAP2, I&rsquo;m not allowed to publish any results. Believe me, it works like üöÄ‚ú®ü™ê.</p>
<p>A language model is trained on large amounts of textual data to understand the patterns and structure of language. The primary goal of a language model is to predict the probability of the next word or sequence of words in a sentence given the previous words.</p>
<p>Language models can be used for a variety of natural language processing (NLP) tasks, such as text classification, machine translation, text summarization, speech recognition, and sentiment analysis. There are many types of language models, ranging from simple n-gram models to more complex neural network-based models such as recurrent neural networks (RNNs) and transformers.</p>
<p>The transformer architecture is currently mostly used for language models and can be divided into an encoder and/or decoder architecture depending on the specific task. In general, transformers are trained on a large quantity of unlabeled text using self-supervised learning. The training of a transformer model on a lot of data takes a lot of computational effort and the training of language models can get expensive very quickly. So, often the best way to have a task-specific transformer model is to use a pre-trained model from <a href="https://huggingface.co/">Hugging Face</a> and fine-tune the model based on your data.</p>
<p>Based on my work experience with invoices, fine-tuning a pre-existing model didn&rsquo;t work well. I received the best results for text classification after fine-tuning a french base-model on german invoices. Nevertheless the overall F1-score wasn&rsquo;t worth the effort. I assume that the content and structure of an invoice differs too much from the training data (e.g. no continuous text and many numbers). Additional, the tokenizers of the pre-trained models are not optimied for invoices, so the context window of a transformer will contain less text, which makes the training less effective.</p>
<p>I worked on text classification of invoices for multiple clients. I trained a base-model on a few million invoices (mostly german and english) and fine-tuned the base model for each client with around 2000 - 50000 invoices and 70 - 2000 labels. Initially I used the Longformer architecture (<a href="https://arxiv.org/pdf/2004.05150.pdf">Beltagy et al. 2020</a>), but a <a href="https://github.com/pytorch/pytorch/issues/94810">bug</a> prevented the model deployment. Besides its limitations, I used the BERT architecture <a href="https://arxiv.org/pdf/1810.04805.pdf">Devlin et al. 2019</a>. <a href="https://huggingface.co/blog/how-to-train">Hugging Face</a> also provides a tutorial for training language models. .</p>
<h2 id="tokenizer">Tokenizer<a hidden class="anchor" aria-hidden="true" href="#tokenizer">#</a></h2>
<p>A tokenizer converts raw text into smaller units, such as words or subwords, that can be used for training machine learning models. The tokenizer takes as input a string of text and outputs a sequence of tokens, each of which represents a distinct unit of meaning. The subword tokenizer breaks down words into smaller subword units. This is useful for handling out-of-vocabulary (OOV) words, which are words that are not in the training data.</p>
<p>The <a href="https://huggingface.co/course/chapter6/5?fw=pt">Byte-Pair Encoding tokenizer</a> replaces the most common pair of consecutive bytes with bytes that does not occur in that data (<a href="https://www.derczynski.com/papers/archive/BPE_Gage.pdf">Gage 1994</a>, <a href="https://arxiv.org/pdf/1508.07909.pdf">Sennrich et al. 2016</a>).</p>
<p>First, we define our BPE tokenizer with the preprocessing steps for the incoming text data. As normalization we use unicode-normalization and set the text to lower case. Further  preprocessing steps are  a ByteLevel representation of the text followed by splitting the text by whitespaces. As a last step, we decode a tokenized input to the original one.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers <span style="color:#f92672">import</span> normalizers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers.decoders <span style="color:#f92672">import</span> ByteLevel <span style="color:#66d9ef">as</span> ByteLevelDecoder
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers.normalizers <span style="color:#f92672">import</span> NFD, Lowercase, NFKC
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers <span style="color:#f92672">import</span> pre_tokenizers
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers.pre_tokenizers <span style="color:#f92672">import</span> Whitespace, ByteLevel
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> tokenizers <span style="color:#f92672">import</span> Tokenizer, models, trainers
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer <span style="color:#f92672">=</span> Tokenizer(models<span style="color:#f92672">.</span>BPE())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>normalizer <span style="color:#f92672">=</span> normalizers<span style="color:#f92672">.</span>Sequence([
</span></span><span style="display:flex;"><span>    NFD(),
</span></span><span style="display:flex;"><span>    Lowercase()
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Our tokenizer also needs a pre-tokenizer responsible for converting the input to a ByteLevel representation.</span>
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>pre_tokenizer <span style="color:#f92672">=</span> pre_tokenizers<span style="color:#f92672">.</span>Sequence([
</span></span><span style="display:flex;"><span>                                        ByteLevel(add_prefix_space<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>),
</span></span><span style="display:flex;"><span>                                        Whitespace()
</span></span><span style="display:flex;"><span>                                        ])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>decoder <span style="color:#f92672">=</span> ByteLevelDecoder()
</span></span></code></pre></td></tr></table>
</div>
</div><p>We define the vocabulary size of the tokenizer, add the special tokens and define the initial alphabet. The provided batch iterator trains the tokenizer from our streaming data.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers.models.gpt2.tokenization_gpt2 <span style="color:#f92672">import</span> bytes_to_unicode
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">batch_iterator</span>(batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> tqdm(range(<span style="color:#ae81ff">0</span>, round(train_length,<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>), batch_size)):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">yield</span> [next(iter_dataset)[<span style="color:#e6db74">&#39;text&#39;</span>] <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(batch_size)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">32768</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>byte_to_unicode_map <span style="color:#f92672">=</span> bytes_to_unicode()
</span></span><span style="display:flex;"><span>unicode_to_byte_map <span style="color:#f92672">=</span> dict((v, k) <span style="color:#66d9ef">for</span> k, v <span style="color:#f92672">in</span> byte_to_unicode_map<span style="color:#f92672">.</span>items())
</span></span><span style="display:flex;"><span>base_vocab <span style="color:#f92672">=</span> list(unicode_to_byte_map<span style="color:#f92672">.</span>keys())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> trainers<span style="color:#f92672">.</span>BpeTrainer(vocab_size<span style="color:#f92672">=</span>vocab_size,
</span></span><span style="display:flex;"><span>                              show_progress<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>                              initial_alphabet<span style="color:#f92672">=</span>base_vocab,
</span></span><span style="display:flex;"><span>                              special_tokens<span style="color:#f92672">=</span>[<span style="color:#e6db74">&#34;[UNK]&#34;</span>, <span style="color:#e6db74">&#34;[CLS]&#34;</span>, <span style="color:#e6db74">&#34;[SEP]&#34;</span>, <span style="color:#e6db74">&#34;[PAD]&#34;</span>, <span style="color:#e6db74">&#34;[MASK]&#34;</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>iter_dataset <span style="color:#f92672">=</span> iter(train_dataset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>tokenizer<span style="color:#f92672">.</span>train_from_iterator(batch_iterator(), trainer<span style="color:#f92672">=</span>trainer)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Here is an example of the tokenizer output</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>output <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(output<span style="color:#f92672">.</span>tokens)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> [<span style="color:#e6db74">&#39;die&#39;</span>, <span style="color:#e6db74">&#39;ƒ†authent&#39;</span>, <span style="color:#e6db74">&#39;if&#39;</span>, <span style="color:#e6db74">&#39;ikation&#39;</span>, <span style="color:#e6db74">&#39;ƒ†wird&#39;</span>, <span style="color:#e6db74">&#39;ƒ†mit&#39;</span>, <span style="color:#e6db74">&#39;ƒ†open&#39;</span>, <span style="color:#e6db74">&#39;l&#39;</span>, <span style="color:#e6db74">&#39;da&#39;</span>, <span style="color:#e6db74">&#39;p&#39;</span>, <span style="color:#e6db74">&#39;ƒ†erledigt&#39;</span>, <span style="color:#e6db74">&#39;,&#39;</span>, <span style="color:#e6db74">&#39;ƒ†die&#39;</span>, <span style="color:#e6db74">&#39;ƒ†einrichtung&#39;</span>, <span style="color:#e6db74">&#39;ƒ†oder&#39;</span>, <span style="color:#e6db74">&#39;ƒ†aktualisierung&#39;</span>, <span style="color:#e6db74">&#39;ƒ†von&#39;</span>, <span style="color:#e6db74">&#39;ƒ†systemen&#39;</span>, <span style="color:#e6db74">&#39;ƒ†mit&#39;</span>, <span style="color:#e6db74">&#39;ƒ†y&#39;</span>, <span style="color:#e6db74">&#39;um&#39;</span>, <span style="color:#e6db74">&#39;ƒ†und&#39;</span>, <span style="color:#e6db74">&#39;ƒ†servern&#39;</span>, <span style="color:#e6db74">&#39;ƒ†f√É&#39;</span>, <span style="color:#e6db74">&#39;¬º&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>, <span style="color:#e6db74">&#39;ƒ†dns&#39;</span>, <span style="color:#e6db74">&#39;,&#39;</span>, <span style="color:#e6db74">&#39;ƒ†d&#39;</span>, <span style="color:#e6db74">&#39;hc&#39;</span>, <span style="color:#e6db74">&#39;p&#39;</span>, <span style="color:#e6db74">&#39;ƒ†und&#39;</span>, <span style="color:#e6db74">&#39;ƒ†t&#39;</span>, <span style="color:#e6db74">&#39;ft&#39;</span>, <span style="color:#e6db74">&#39;p&#39;</span>, <span style="color:#e6db74">&#39;.&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(output<span style="color:#f92672">.</span>ids)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> [<span style="color:#ae81ff">373</span>, <span style="color:#ae81ff">12466</span>, <span style="color:#ae81ff">997</span>, <span style="color:#ae81ff">2887</span>, <span style="color:#ae81ff">468</span>, <span style="color:#ae81ff">341</span>, <span style="color:#ae81ff">4256</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">609</span>, <span style="color:#ae81ff">84</span>, <span style="color:#ae81ff">11738</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">282</span>, <span style="color:#ae81ff">9128</span>, <span style="color:#ae81ff">550</span>, <span style="color:#ae81ff">19260</span>, <span style="color:#ae81ff">355</span>, <span style="color:#ae81ff">18058</span>, <span style="color:#ae81ff">341</span>, <span style="color:#ae81ff">1312</span>, <span style="color:#ae81ff">349</span>, <span style="color:#ae81ff">309</span>, <span style="color:#ae81ff">20238</span>, <span style="color:#ae81ff">348</span>, <span style="color:#ae81ff">125</span>, <span style="color:#ae81ff">86</span>, <span style="color:#ae81ff">31306</span>, <span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">264</span>, <span style="color:#ae81ff">25171</span>, <span style="color:#ae81ff">84</span>, <span style="color:#ae81ff">309</span>, <span style="color:#ae81ff">328</span>, <span style="color:#ae81ff">367</span>, <span style="color:#ae81ff">84</span>, <span style="color:#ae81ff">18</span>]
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="data-pipeline">Data pipeline<a hidden class="anchor" aria-hidden="true" href="#data-pipeline">#</a></h2>
<p>The training data is stored in multiple parquet files and split into a training and evaluation dataset in a preprocessing step. I used a train-test split of 0.01. Since the data doesn&rsquo;t fit into memory, the data is streaming from disk. The text will be padded or truncated to the defined context length.
The data collator for masked language modeling masks the incoming text data to allow the model training.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> datasets <span style="color:#f92672">import</span> load_dataset
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> DataCollatorForLanguageModeling
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_dataset <span style="color:#f92672">=</span> load_dataset(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;parquet&#39;</span>, data_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;train_data/&#34;</span>,
</span></span><span style="display:flex;"><span>    streaming<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    split<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;train&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>eval_dataset <span style="color:#f92672">=</span> load_dataset(
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;parquet&#39;</span>, data_dir<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;eval_data/&#34;</span>,
</span></span><span style="display:flex;"><span>    streaming<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    split<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;train&#34;</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_dataset <span style="color:#f92672">=</span> train_dataset<span style="color:#f92672">.</span>map(
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">lambda</span> x: tokenizer<span style="color:#f92672">.</span>batch_encode_plus(
</span></span><span style="display:flex;"><span>        x[<span style="color:#e6db74">&#39;text&#39;</span>],
</span></span><span style="display:flex;"><span>        padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        truncation<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        max_length<span style="color:#f92672">=</span>max_length),
</span></span><span style="display:flex;"><span>    batched<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>eval_dataset <span style="color:#f92672">=</span> eval_dataset<span style="color:#f92672">.</span>map(
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">lambda</span> x: tokenizer<span style="color:#f92672">.</span>batch_encode_plus(
</span></span><span style="display:flex;"><span>        x[<span style="color:#e6db74">&#39;text&#39;</span>],
</span></span><span style="display:flex;"><span>        padding<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        truncation<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>        max_length<span style="color:#f92672">=</span>max_length),
</span></span><span style="display:flex;"><span>    batched<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>train_dataset <span style="color:#f92672">=</span> train_dataset<span style="color:#f92672">.</span>with_format(<span style="color:#e6db74">&#34;torch&#34;</span>)
</span></span><span style="display:flex;"><span>eval_dataset <span style="color:#f92672">=</span> eval_dataset<span style="color:#f92672">.</span>with_format(<span style="color:#e6db74">&#34;torch&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data_collator <span style="color:#f92672">=</span> DataCollatorForLanguageModeling(
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer, mlm<span style="color:#f92672">=</span>use_mlm, mlm_probability<span style="color:#f92672">=</span>mlm_probability
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="model-training">Model Training<a hidden class="anchor" aria-hidden="true" href="#model-training">#</a></h2>
<p>So far, the data is processed, the data streaming is set up and a tokenizer is trained. Finally the model training can start. I follow the BERT architecture <a href="https://arxiv.org/pdf/1810.04805.pdf">Devlin et al. 2019</a> and use their initial setup and hyperparameters. The model is trained via masked language modelling, where 20 % of the tokens will be randomly masked. From those 20% of masked tokens, 80 % will be untouched, 10 % will be replaced with random tokens and 10 % will be replaced with the original tokens. <a href="https://github.com/huggingface/transformers/blob/main/src/transformers/data/data_collator.py#L607">Hugging Face</a> provides an implementation for it. <a href="https://arxiv.org/pdf/2202.08005.pdf">Wettig et al. 2023</a> scrutinized the impact of the mlm parameters towards the model result.</p>
<p>Here is an example, which shows some randomly mask tokens from an incoming text. The model is trained on predicting the masked tokens based on the context of the whole sentence.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Mask Token id: </span><span style="color:#e6db74">{</span>tokenizer<span style="color:#f92672">.</span>mask_token_id<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> Mask Token id: <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>output <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>encode(<span style="color:#e6db74">&#34;Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>masked <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>sample(range(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">36</span>), <span style="color:#ae81ff">7</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> mask <span style="color:#f92672">in</span> masked:
</span></span><span style="display:flex;"><span>    output[mask] <span style="color:#f92672">=</span> tokenizer<span style="color:#f92672">.</span>mask_token_id
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Masked encoding: </span><span style="color:#e6db74">{</span>tokenizer<span style="color:#f92672">.</span>decode(output)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> Masked encoding: [MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] f[MASK]r dns, dhcp und tftp<span style="color:#f92672">.</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>I&rsquo;m not a big fan of using too many libraries, but I didn&rsquo;t have enough time to set up the BERT model with Pytorch. I go the happy dependancy path and use the <a href="https://github.com/huggingface/transformers">transformer</a> library. Probably, I will create another post, where I describe the transition from the transformer library to plain pytorch.</p>
<p>I use the standard BERT configuration with eight attention layers with eight attention heads for each layer. A context size of 512 will truncate multiple invoices, but some experiments indicate that the overall effect can be neglected on the model performance . To understand the attention mechanism better, please follow my short <a href="https://steffenhaeussler.github.io/posts/attention_layer/">blog post</a>.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> BertConfig, BertForMaskedLM
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>use_mlm <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>mlm_probability <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.2</span> <span style="color:#75715e"># still keeping the 80 - 10 - 10 rule</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>max_length<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>block_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>max_position_embeddings <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>hidden_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">768</span>
</span></span><span style="display:flex;"><span>num_hidden_layers <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>num_attention_heads <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>intermediate_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">3072</span>
</span></span><span style="display:flex;"><span>drop_out <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>config <span style="color:#f92672">=</span> BertConfig(
</span></span><span style="display:flex;"><span><span style="color:#75715e">#   attention_window = [block_size]*num_attention_heads,</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#   mask_token_id = 4,</span>
</span></span><span style="display:flex;"><span>    bos_token_id <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>    sep_token_id <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span><span style="color:#75715e">#   pad_token_id = 3,</span>
</span></span><span style="display:flex;"><span>    eos_token_id <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    max_position_embeddings <span style="color:#f92672">=</span> max_position_embeddings,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    hidden_size <span style="color:#f92672">=</span> hidden_size,
</span></span><span style="display:flex;"><span>    num_hidden_layers <span style="color:#f92672">=</span> num_hidden_layers,
</span></span><span style="display:flex;"><span>    num_attention_heads <span style="color:#f92672">=</span> num_attention_heads,
</span></span><span style="display:flex;"><span>    intermediate_size <span style="color:#f92672">=</span> intermediate_size,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    hidden_act <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;gelu&#39;</span>,
</span></span><span style="display:flex;"><span>    hidden_dropout_prob <span style="color:#f92672">=</span> drop_out,
</span></span><span style="display:flex;"><span>    attention_probs_dropout_prob <span style="color:#f92672">=</span> drop_out,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    type_vocab_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>    initializer_range <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.02</span>,
</span></span><span style="display:flex;"><span>    layer_norm_eps <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-12</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    vocab_size <span style="color:#f92672">=</span> vocab_size,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    use_cache <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    classifier_dropout <span style="color:#f92672">=</span> <span style="color:#66d9ef">None</span>,
</span></span><span style="display:flex;"><span>    onnx_export <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> BertForMaskedLM(config<span style="color:#f92672">=</span>config)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;n of parameters: </span><span style="color:#e6db74">{</span>model<span style="color:#f92672">.</span>num_parameters()<span style="color:#e6db74">:</span><span style="color:#e6db74">_</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> n of parameters: <span style="color:#ae81ff">82_820_774</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The model will use 82 million parameters. Depending on the data size and GPUs, it will train less than 1,5 weeks on 4x T4 GPUs. The model train for five epochs with the AdamW optimizer <a href="https://arxiv.org/pdf/1711.05101.pdf">Loshchilov &amp; Hutter 2019</a> and used the learning rate published in the BERT paper with the same weight decay parameters. The batch size is optimized for maximum utilization of the GPU memory. The gradient accumulation step updates the model weights with a batch size of 64. To speed up training, we use fp16.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> Trainer, TrainingArguments, EarlyStoppingCallback
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>learning_rate <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-4</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>weight_decay <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-2</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>lr_scheduler_type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;linear&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>num_train_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>train_batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>
</span></span><span style="display:flex;"><span>eval_batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">32</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gradient_accumulation_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>eval_accumulation_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>warmup_steps <span style="color:#f92672">=</span> <span style="color:#ae81ff">1_000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>adam_beta1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.9</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>adam_beta2 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.999</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>adam_epsilon <span style="color:#f92672">=</span> <span style="color:#ae81ff">1e-8</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>max_grad_norm <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#75715e"># bert</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>max_steps<span style="color:#f92672">=</span>num_train_epochs<span style="color:#f92672">*</span>train_length<span style="color:#f92672">//</span>train_batch_size
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>training_args <span style="color:#f92672">=</span> TrainingArguments(
</span></span><span style="display:flex;"><span>    output_dir<span style="color:#f92672">=</span>model_path,
</span></span><span style="display:flex;"><span>    overwrite_output_dir<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    learning_rate<span style="color:#f92672">=</span>learning_rate,
</span></span><span style="display:flex;"><span>    weight_decay<span style="color:#f92672">=</span>weight_decay,
</span></span><span style="display:flex;"><span>    lr_scheduler_type<span style="color:#f92672">=</span>lr_scheduler_type,
</span></span><span style="display:flex;"><span>    num_train_epochs<span style="color:#f92672">=</span>num_train_epochs,
</span></span><span style="display:flex;"><span>    adam_beta1<span style="color:#f92672">=</span>adam_beta1,
</span></span><span style="display:flex;"><span>    adam_beta2<span style="color:#f92672">=</span>adam_beta2,
</span></span><span style="display:flex;"><span>    adam_epsilon<span style="color:#f92672">=</span>adam_epsilon,
</span></span><span style="display:flex;"><span>    max_grad_norm<span style="color:#f92672">=</span>max_grad_norm,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    evaluation_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;steps&#34;</span>,
</span></span><span style="display:flex;"><span>    eval_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">5_000</span>,
</span></span><span style="display:flex;"><span>    max_steps<span style="color:#f92672">=</span>max_steps,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    per_device_train_batch_size<span style="color:#f92672">=</span>train_batch_size, <span style="color:#75715e"># depends on memory</span>
</span></span><span style="display:flex;"><span>    per_device_eval_batch_size<span style="color:#f92672">=</span>eval_batch_size,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    gradient_accumulation_steps<span style="color:#f92672">=</span>gradient_accumulation_steps,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    save_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;steps&#34;</span>,
</span></span><span style="display:flex;"><span>    save_steps<span style="color:#f92672">=</span><span style="color:#ae81ff">5_000</span>,
</span></span><span style="display:flex;"><span>    save_total_limit<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    prediction_loss_only<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    report_to<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;tensorboard&#34;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    log_level<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;warning&#34;</span>,
</span></span><span style="display:flex;"><span>    logging_strategy<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;steps&#34;</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    fp16 <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    fp16_full_eval<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    load_best_model_at_end<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>    metric_for_best_model<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;loss&#34;</span>,
</span></span><span style="display:flex;"><span>    greater_is_better<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    push_to_hub<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>,
</span></span><span style="display:flex;"><span>    dataloader_pin_memory<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>,
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>early_stopping <span style="color:#f92672">=</span> EarlyStoppingCallback(early_stopping_patience <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>                                       early_stopping_threshold <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.02</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>callbacks <span style="color:#f92672">=</span> [early_stopping]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer <span style="color:#f92672">=</span> Trainer(
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">=</span>model,
</span></span><span style="display:flex;"><span>    args<span style="color:#f92672">=</span>training_args,
</span></span><span style="display:flex;"><span>    data_collator<span style="color:#f92672">=</span>data_collator,
</span></span><span style="display:flex;"><span>    train_dataset<span style="color:#f92672">=</span>train_dataset,
</span></span><span style="display:flex;"><span><span style="color:#75715e">#     compute_metrics=compute_metrics,</span>
</span></span><span style="display:flex;"><span>    eval_dataset<span style="color:#f92672">=</span>eval_dataset,
</span></span><span style="display:flex;"><span>    tokenizer<span style="color:#f92672">=</span>tokenizer,
</span></span><span style="display:flex;"><span>    callbacks<span style="color:#f92672">=</span>callbacks
</span></span><span style="display:flex;"><span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Finally, everything is set up, and we can train our model. Depending on the data, model, and budget size, you can enjoy your holidays, and hopefully, the model training is finished, when you come back.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>trainer<span style="color:#f92672">.</span>save_model(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>model_path<span style="color:#e6db74">}</span><span style="color:#e6db74">/main/&#34;</span>)
</span></span></code></pre></td></tr></table>
</div>
</div><p>As a final step, we can evaluate the model output. Since I can&rsquo;t share any data, I use the output from my Kaggle notebook. For</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">83
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">84
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">85
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">86
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">87
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">88
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">89
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">90
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">91
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">92
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">93
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> pipeline
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>original_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;Die Authentifikation wird mit OpenLDAP erledigt, die Einrichtung oder Aktualisierung von Systemen mit Yum und Servern f√ºr DNS, DHCP und TFTP.&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>masked_text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] f[MASK]r dns, dhcp und tftp.&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mask_filler <span style="color:#f92672">=</span> pipeline(<span style="color:#e6db74">&#34;fill-mask&#34;</span>,<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{</span>model_path<span style="color:#e6db74">}</span><span style="color:#e6db74">/main/&#34;</span>)
</span></span><span style="display:flex;"><span>mask_filler(tokenizer<span style="color:#f92672">.</span>decode(output), top_k<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span> [[{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.8014500737190247</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">373</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;die&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;die[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.08444128930568695</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">517</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;eine&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;eine[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.028047803789377213</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">1384</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;diese&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;diese[MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.03110463358461857</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">4354</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;zert&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK]zertifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.030949348583817482</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">1160</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; ant&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK] antifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.02660573646426201</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">12466</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; authent&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK] authentifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.021829063072800636</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">1202</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; per&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit perldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.018226258456707</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">307</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; p&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit pldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.013632726855576038</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">276</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; m&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit mldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.46616730093955994</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">489</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; einer&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung einer aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.26918938755989075</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">288</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; der&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung der aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.05999871343374252</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">533</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; zur&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung zur aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.19769684970378876</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">2150</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; nov&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit novum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.03822920098900795</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">1504</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; vol&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit volum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.030768193304538727</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">17401</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; quant&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit quantum und[MASK] fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.0999603122472763</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">386</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; dem&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und dem fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.07762913405895233</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">288</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; der&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und der fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.055170487612485886</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">332</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; den&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und den fÔøΩ[MASK]r dns, dhcp und tftp.&#39;</span>}],
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>  [{<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.690095841884613</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">125</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;ÔøΩ&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩÔøΩr dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.029322009533643723</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">12</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39;(&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ(r dns, dhcp und tftp.&#39;</span>},
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>   {<span style="color:#e6db74">&#39;score&#39;</span>: <span style="color:#ae81ff">0.01887478120625019</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token&#39;</span>: <span style="color:#ae81ff">4585</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;token_str&#39;</span>: <span style="color:#e6db74">&#39; pet&#39;</span>,
</span></span><span style="display:flex;"><span><span style="color:#f92672">&gt;&gt;</span>    <span style="color:#e6db74">&#39;sequence&#39;</span>: <span style="color:#e6db74">&#39;[MASK][MASK]ifikation wird mit[MASK]ldap erledigt, die einrichtung[MASK] aktualisierung von systemen mit[MASK]um und[MASK] fÔøΩ petr dns, dhcp und tftp.&#39;</span>}]]
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="fine-tuning">Fine-tuning<a hidden class="anchor" aria-hidden="true" href="#fine-tuning">#</a></h2>
<p>For fine-tuning the language model, you can use the script above. The pre-trained model weights can be loaded into a classification model. The BertForSequenceClassification changes only the head from a MaskedLMHead to a ClassifierHead. All the other model weights will stay the same. Also, the data collator has to be adapted, and we output some metrics for the evaluation. That&rsquo;s all.</p>
<div class="highlight"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> sklearn.metrics <span style="color:#f92672">import</span> f1_score, precision_score, recall_score, accuracy_score
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> transformers <span style="color:#f92672">import</span> BertForSequenceClassification, DataCollatorWithPadding
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_metrics</span>(eval_pred):
</span></span><span style="display:flex;"><span>    logits, labels <span style="color:#f92672">=</span> eval_pred
</span></span><span style="display:flex;"><span>    predictions <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>argmax(logits, axis<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    accuracy <span style="color:#f92672">=</span> accuracy_score(y_true<span style="color:#f92672">=</span>labels, y_pred<span style="color:#f92672">=</span>predictions)
</span></span><span style="display:flex;"><span>    recall <span style="color:#f92672">=</span> recall_score(y_true<span style="color:#f92672">=</span>labels, y_pred<span style="color:#f92672">=</span>predictions, average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)
</span></span><span style="display:flex;"><span>    precision <span style="color:#f92672">=</span> precision_score(y_true<span style="color:#f92672">=</span>labels, y_pred<span style="color:#f92672">=</span>predictions, average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)
</span></span><span style="display:flex;"><span>    f1 <span style="color:#f92672">=</span> f1_score(y_true<span style="color:#f92672">=</span>labels, y_pred<span style="color:#f92672">=</span>predictions, average<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;weighted&#39;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {<span style="color:#e6db74">&#34;accuracy&#34;</span>: accuracy, <span style="color:#e6db74">&#34;precision&#34;</span>: precision, <span style="color:#e6db74">&#34;recall&#34;</span>: recall, <span style="color:#e6db74">&#34;f1&#34;</span>: f1}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data_collator <span style="color:#f92672">=</span> DataCollatorWithPadding(tokenizer<span style="color:#f92672">=</span>tokenizer, pad_to_multiple_of<span style="color:#f92672">=</span>block_size)
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> BertForSequenceClassification<span style="color:#f92672">.</span>from_pretrained(model_path, num_labels<span style="color:#f92672">=</span>num_label)
</span></span></code></pre></td></tr></table>
</div>
</div><p>Thank you for your attention.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://steffenhaeussler.github.io/tags/nlp/">Nlp</a></li>
      <li><a href="https://steffenhaeussler.github.io/tags/transformer/">Transformer</a></li>
      <li><a href="https://steffenhaeussler.github.io/tags/machine-learning/">Machine Learning</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://steffenhaeussler.github.io/">About me</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>

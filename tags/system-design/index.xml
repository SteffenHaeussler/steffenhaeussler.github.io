<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>System Design on About me</title>
    <link>https://steffenhaeussler.github.io/tags/system-design/</link>
    <description>Recent content in System Design on About me</description>
    <generator>Hugo -- 0.140.1</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 19 Apr 2025 10:30:58 +0100</lastBuildDate>
    <atom:link href="https://steffenhaeussler.github.io/tags/system-design/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Evaluation of RAG systems</title>
      <link>https://steffenhaeussler.github.io/posts/2025-04-30-metrics/metrics/</link>
      <pubDate>Sat, 19 Apr 2025 10:30:58 +0100</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2025-04-30-metrics/metrics/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;The implementation of this article is &lt;a href=&#34;https://www.kaggle.com/code/steffenhaeussler/evaluation-of-rag-systems&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;RAGs are complex systems. This is obvious, when you try to evaluate them. There are multiple aspects, which need to be checked. Here, I try to look into different approaches to get a better understanding and problems, when facing RAG systems. RAG system evaluation involves two distinct parts: retrieval and generation part. For retrieval, context relevance and noise robustness are key factors in assessing quality, while for generation part, key factors like answer faithfulness, answer relevance, negative rejection, information integration, and counterfactual robustness are important (&lt;a href=&#34;https://arxiv.org/pdf/2312.10997#page=14&#34;&gt;Gao et al. 2024&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Get embeddings for multiple data sources</title>
      <link>https://steffenhaeussler.github.io/posts/2025-01-02-embeddings/embeddings/</link>
      <pubDate>Thu, 02 Jan 2025 10:30:58 +0100</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2025-01-02-embeddings/embeddings/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;Following my first short post about &lt;a href=&#34;https://steffenhaeussler.github.io/posts/2024-12-27-overview/rag_overview/&#34;&gt;RAGs&lt;/a&gt;, I would like to provide a brief overview about embeddings, which are used to find similiar objects in a vector database. To better understand how various transformer models handle different input data types, I created this &lt;a href=&#34;https://www.kaggle.com/code/steffenhaeussler/get-embeddings-for-multiple-data-types&#34;&gt;notebook&lt;/a&gt;. I explore therefor, text, image, audio and video data.&lt;/p&gt;
&lt;p&gt;I’ve chosen to skip the more traditional text embeddings (TF-IDF, Word2Vec or GloVe), because there are already very good tutorials available. Additionally, I plan to discuss the training of embedding models in a separate blog post. For this post, I use mostly pretrained classification models, where I use the last layer before the prediction head as embedding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Overview of RAG (Retrieval-Augmented Generation) systems</title>
      <link>https://steffenhaeussler.github.io/posts/2024-12-27-overview/rag_overview/</link>
      <pubDate>Fri, 27 Dec 2024 10:30:58 +0100</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2024-12-27-overview/rag_overview/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;It’s been a while since my last post, mostly because of my own laziness. Over the past year, I’ve been working on several projects, one of which is a small RAG (Retrieval-Augmented Generation) system. I implemented it to combine external knowledge (in this case internal safety documents) with a large language model (LLM). This approach allows the use of data that the LLM wasn&amp;rsquo;t trained on and also helps reduce hallucinations.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

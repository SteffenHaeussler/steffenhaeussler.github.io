<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>data science on About me</title>
    <link>https://steffenhaeussler.github.io/tags/data-science/</link>
    <description>Recent content in data science on About me</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Dec 2023 10:30:58 +0100</lastBuildDate><atom:link href="https://steffenhaeussler.github.io/tags/data-science/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deep Learning model explainability</title>
      <link>https://steffenhaeussler.github.io/posts/dl_model_explainability/</link>
      <pubDate>Fri, 08 Dec 2023 10:30:58 +0100</pubDate>
      
      <guid>https://steffenhaeussler.github.io/posts/dl_model_explainability/</guid>
      <description>Hi,
In my first post, I looked into the explainability of classical machine learning models. As a next step, I&amp;rsquo;m interested in the explainability of neural networks. Model explainability is easy for simple models (linear regression, decision trees), and some tools exist for more complex algorithms (ensemble trees). Therefore, I highly recommend the book Interpretable Machine Learning by Christoph Molnar for a deeper theoretical understanding. All different approaches for model explanability are shown with a PyTorch model in this kaggle notebook.</description>
    </item>
    
    <item>
      <title>Model explainability</title>
      <link>https://steffenhaeussler.github.io/posts/model_explainability/</link>
      <pubDate>Tue, 21 Nov 2023 10:30:58 +0100</pubDate>
      
      <guid>https://steffenhaeussler.github.io/posts/model_explainability/</guid>
      <description>Hi,
Some months have passed since my last post. Model explainability is easy for simple models (linear regression, decision trees), and some tools exist for more complex algorithms (ensemble trees). I want to dig into the tools to interpret more complex models with this post. Therefore, I highly recommend the book Interpretable Machine Learning by Christoph Molnar for a deeper theoretical understanding. All different approaches for model explanability are shown with a RandomForest model in this kaggle notebook.</description>
    </item>
    
    <item>
      <title>Cookie-cutter Problems</title>
      <link>https://steffenhaeussler.github.io/posts/cookiecutter/</link>
      <pubDate>Mon, 10 Apr 2023 10:30:58 +0100</pubDate>
      
      <guid>https://steffenhaeussler.github.io/posts/cookiecutter/</guid>
      <description>Hi,
Recently, I started to put some scripts together and run them against a Kaggle dataset. I decided to train my skills on an unseen dataset. Training keeps me sharp, and I need it to complement my skill set. For the last 2,5 years, I struggled in a small team with NLP problems, where I worked mostly on engineering tasks. My understanding in this area is not where I wanted to be.</description>
    </item>
    
    <item>
      <title>Cookie-cutter Problems</title>
      <link>https://steffenhaeussler.github.io/projects/cookiecutter/</link>
      <pubDate>Mon, 10 Apr 2023 10:30:58 +0100</pubDate>
      
      <guid>https://steffenhaeussler.github.io/projects/cookiecutter/</guid>
      <description>Hi,
Recently, I started to put some scripts together and run them against a Kaggle dataset. I decided to train my skills on an unseen dataset. Training keeps me sharp, and I need it to complement my skill set. For the last 2,5 years, I struggled in a small team with NLP problems, where I worked mostly on engineering tasks. My understanding in this area is not where I wanted to be.</description>
    </item>
    
    <item>
      <title>Stratified multi-label split</title>
      <link>https://steffenhaeussler.github.io/posts/multi_label_split/</link>
      <pubDate>Sat, 08 Apr 2023 10:30:58 +0100</pubDate>
      
      <guid>https://steffenhaeussler.github.io/posts/multi_label_split/</guid>
      <description>Hi,
This post is a short overview of a stratified multi-label train-test split. Please look at the colab implementation for a step through guide.
Sometimes you step into work problems, which justify a small post. I already saw colleagues struggling to balance the train-test split for multi-label classification. In classification problems, we have often a dataset with an imbalanced number of classes. In general, it is desired to keep the proportions of each label for the train and test sets as observed as in the original dataset.</description>
    </item>
    
  </channel>
</rss>

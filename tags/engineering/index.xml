<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Engineering on About me</title>
    <link>https://steffenhaeussler.github.io/tags/engineering/</link>
    <description>Recent content in Engineering on About me</description>
    <generator>Hugo -- 0.147.5</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Aug 2023 10:30:50 +0200</lastBuildDate>
    <atom:link href="https://steffenhaeussler.github.io/tags/engineering/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Endpoint validation</title>
      <link>https://steffenhaeussler.github.io/posts/2023-08-07-pydantic/pydantic/</link>
      <pubDate>Mon, 07 Aug 2023 10:30:50 +0200</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2023-08-07-pydantic/pydantic/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;In my previous job, I spent hours debugging internal data transformations to figure out the received data from an external API was faulty. This issue would not appeared with schema validation. My fault was that I trusted the incoming data and didnâ€™t check for data consistency. Learning from mistakes and saving time, I would set up a small example for JSON validation via Pydantic. FastAPI relies heavily on pydantic and I use it for validating the incoming request and outgoing response. Anyway, not in every project FastAPI is used.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Fast data transfer to or from s3</title>
      <link>https://steffenhaeussler.github.io/posts/2023-04-27-s3/s3/</link>
      <pubDate>Thu, 27 Apr 2023 10:30:58 +0100</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2023-04-27-s3/s3/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;This post is an homage to a &lt;a href=&#34;https://stackoverflow.com/questions/56639630/how-can-i-increase-my-aws-s3-upload-speed-when-using-boto3/61809946#61809946&#34;&gt;stackoverflow post&lt;/a&gt; copying data from s3. This shared work saved me a lot of time. I believe that individuals who share their work do not receive sufficient recognition.&lt;/p&gt;
&lt;p&gt;The problem is that I have multiple Gb of data separated into thousands of files. Those files are selected for download by the semi-automated pipeline for model training. So the number of files to download varies from pipeline run to pipeline run. Also, this makes any data preparation obsolete. The solution from the &lt;a href=&#34;https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-example-download-file.html&#34;&gt;official boto3 documentation&lt;/a&gt; for copying data from s3 takes too long. Even with &lt;a href=&#34;https://docs.python.org/3/library/concurrent.futures.html&#34;&gt;asynchronous execution&lt;/a&gt; in the download, it will take a few hours to download those files.  Imagine a scenario where you want to fine-tune a deep learning model on a machine with multiple GPUs, but you have to wait several hours for the data to be copied ðŸ˜±. Any preprocessing steps are not feasible since the data is filtered upon request. Additionally, downloading the data via aws cli is not an option, as there is much more data in the s3 buckets than requested for model training. The simplest approach is to increase the throughput. And here is the beauty, directly copy+pasted from &lt;a href=&#34;https://stackoverflow.com/questions/56639630/how-can-i-increase-my-aws-s3-upload-speed-when-using-boto3/61809946#61809946&#34;&gt;Pierre D&lt;/a&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The importance of building things by yourself</title>
      <link>https://steffenhaeussler.github.io/posts/2023-03-05-first/first/</link>
      <pubDate>Sun, 05 Mar 2023 23:30:58 +0100</pubDate>
      <guid>https://steffenhaeussler.github.io/posts/2023-03-05-first/first/</guid>
      <description>&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;In this initial post, I want to draft the development of my &lt;a href=&#34;https://github.com/SteffenHaeussler/fastapi_skeleton/&#34;&gt;FastAPI skeleton&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;At the beginning of my career as a Data Scientist, I ran into the typical problem of model deployment to production.
In a team of two scientists, I had the chance to write a micro-service &lt;a href=&#34;https://github.com/SteffenHaeussler/flask_skeleton&#34;&gt;with Flask from scratch&lt;/a&gt; out of necessity.&lt;/p&gt;
&lt;p&gt;My first service followed strongly the example of &lt;a href=&#34;https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world&#34;&gt;Miguel Grinbergs great tutorial&lt;/a&gt;. The reason was simple, I couldn&amp;rsquo;t write proper code at this time. Besides no experience and the great help of my co-workers, I could write a production-ready micro-service in a few weeks with the following features:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
